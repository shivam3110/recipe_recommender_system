{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT subword tokenizer with start-of-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.3.min.js\", \"https://cdn.holoviz.org/panel/1.6.1/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='0f3446a4-2460-468b-8f32-f87344acda69'>\n",
       "  <div id=\"b3cddde5-0c2f-457f-bac2-475e01bc8204\" data-root-id=\"0f3446a4-2460-468b-8f32-f87344acda69\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"23db94e5-eddd-44c4-8431-8e19bb9c69dc\":{\"version\":\"3.6.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"0f3446a4-2460-468b-8f32-f87344acda69\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"0799c92f-f5dc-4bc0-b823-b72e1ad443c1\",\"attributes\":{\"plot_id\":\"0f3446a4-2460-468b-8f32-f87344acda69\",\"comm_id\":\"721f8cacdcad401cb05c685b52c8f54b\",\"client_comm_id\":\"b7167ce9fefc4f0bba4c18b312bfe965\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"23db94e5-eddd-44c4-8431-8e19bb9c69dc\",\"roots\":{\"0f3446a4-2460-468b-8f32-f87344acda69\":\"b3cddde5-0c2f-457f-bac2-475e01bc8204\"},\"root_ids\":[\"0f3446a4-2460-468b-8f32-f87344acda69\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "0f3446a4-2460-468b-8f32-f87344acda69"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import hvplot.pandas  # Provides hvplot accessor to Pandas DataFrames\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "DATA_DIR = Path(r\"D:\\UKW_work\\code\\recipe_recommender_system\\data\\food_com_GeniusKitchen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import torch\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import OpenAIGPTTokenizer, OpenAIGPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "recepies_token = pd.read_csv( DATA_DIR / 'PP_recipes.csv')\n",
    "recepies_token_subset = recepies_token.head(10)  \n",
    "recepies_token_subset.to_csv(r'D:\\UKW_work\\code\\recipe_recommender_system\\temp\\recepies_token_subset.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_token = pd.read_csv( DATA_DIR / 'PP_users.csv')\n",
    "users_token_subset = users_token.head(10)  \n",
    "users_token_subset.to_csv(r'D:\\UKW_work\\code\\recipe_recommender_system\\temp\\users_token_subset.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 1. Load and Explore the Data Files\n",
    "#########################################\n",
    "# Load PP_users.csv and PP_recipes.csv (adjust file paths if necessary)\n",
    "users_df = pd.read_csv( DATA_DIR / 'PP_users.csv')\n",
    "recipes_df = pd.read_csv( DATA_DIR / 'PP_recipes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP_users.csv columns: ['u', 'techniques', 'items', 'n_items', 'ratings', 'n_ratings']\n",
      "PP_users.csv shape: (25076, 6)\n",
      "PP_recipes.csv columns: ['id', 'i', 'name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'calorie_level', 'ingredient_ids']\n",
      "PP_recipes.csv shape: (178265, 8)\n"
     ]
    }
   ],
   "source": [
    "# Display column names and shapes\n",
    "print(\"PP_users.csv columns:\", users_df.columns.tolist())\n",
    "print(\"PP_users.csv shape:\", users_df.shape)\n",
    "print(\"PP_recipes.csv columns:\", recipes_df.columns.tolist())\n",
    "print(\"PP_recipes.csv shape:\", recipes_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 2. Process PP_users.csv into Interaction Data\n",
    "#########################################\n",
    "# Expected columns in PP_users.csv:\n",
    "#   u               : User ID (mapped to contiguous integers)\n",
    "#   items           : Recipes interacted with (aggregated; stored as a list in string form)\n",
    "#   ratings         : Ratings given to each recipe (list in string form)\n",
    "#   techniques, n_items, n_ratings are also available but not used directly for recommendations.\n",
    "# Parse the 'items' and 'ratings' columns from string to Python lists.\n",
    "users_df['items'] = users_df['items'].apply(ast.literal_eval)\n",
    "users_df['ratings'] = users_df['ratings'].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample interactions:\n",
      "   user_id  recipe_id  rating\n",
      "0        0       1118     5.0\n",
      "1        0      27680     5.0\n",
      "2        0      32541     5.0\n",
      "3        0     137353     5.0\n",
      "4        0      16428     5.0\n",
      "Total interactions: 698901\n"
     ]
    }
   ],
   "source": [
    "# Build an \"exploded\" interactions DataFrame: one row per (user, recipe, rating)\n",
    "interaction_list = []\n",
    "for _, row in users_df.iterrows():\n",
    "    user_id = row['u']\n",
    "    for recipe_id, rating in zip(row['items'], row['ratings']):\n",
    "        interaction_list.append({'user_id': user_id, 'recipe_id': recipe_id, 'rating': rating})\n",
    "interactions_df = pd.DataFrame(interaction_list)\n",
    "print(\"\\nSample interactions:\")\n",
    "print(interactions_df.head())\n",
    "print(\"Total interactions:\", interactions_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of users: 25076, Number of recipes: 178263\n",
      "User-Item Sparse Matrix shape: (25076, 178263)\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 3. Build a Sparse Userâ€“Item Rating Matrix\n",
    "#########################################\n",
    "# Determine the number of users and recipes.\n",
    "n_users = interactions_df['user_id'].max() + 1\n",
    "n_recipes = interactions_df['recipe_id'].max() + 1\n",
    "print(f\"\\nNumber of users: {n_users}, Number of recipes: {n_recipes}\")\n",
    "\n",
    "# Create arrays for constructing a sparse matrix.\n",
    "row_indices = interactions_df['user_id'].values\n",
    "col_indices = interactions_df['recipe_id'].values\n",
    "ratings = interactions_df['rating'].values\n",
    "\n",
    "# Build a CSR (Compressed Sparse Row) matrix.\n",
    "user_item_sparse = csr_matrix((ratings, (row_indices, col_indices)), shape=(n_users, n_recipes))\n",
    "print(\"User-Item Sparse Matrix shape:\", user_item_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 4. Collaborative Filtering: On-The-Fly Similarity\n",
    "#########################################\n",
    "def recommend_collaborative(user_id, top_k=5):\n",
    "    \"\"\"\n",
    "    Recommend recipes for a given user using collaborative filtering.\n",
    "    Computes cosine similarity on the fly between the target user's vector and all user vectors.\n",
    "    Then, aggregates ratings from similar users (weighted by similarity) to score recipes.\n",
    "    Excludes recipes already rated by the target user.\n",
    "    \"\"\"\n",
    "    # Get target user's vector (1 x n_recipes)\n",
    "    user_vec = user_item_sparse.getrow(user_id)\n",
    "    # Compute cosine similarity between this user and all users.\n",
    "    # This returns a dense array of shape (1, n_users)\n",
    "    sim_scores = cosine_similarity(user_vec, user_item_sparse).flatten()\n",
    "    \n",
    "    # Compute a weighted score for each recipe.\n",
    "    # user_item_sparse.T has shape (n_recipes x n_users); dot with sim_scores gives (n_recipes,)\n",
    "    weighted_scores = user_item_sparse.T.dot(sim_scores)\n",
    "    # Normalize by the sum of similarity scores.\n",
    "    weighted_scores = weighted_scores / (sim_scores.sum() + 1e-8)\n",
    "    \n",
    "    # Exclude recipes already rated by the user.\n",
    "    user_rated = set(interactions_df[interactions_df['user_id'] == user_id]['recipe_id'])\n",
    "    candidate_indices = [i for i in range(n_recipes) if i not in user_rated]\n",
    "    \n",
    "    # Get scores for candidates.\n",
    "    candidate_scores = {recipe: weighted_scores[recipe] for recipe in candidate_indices}\n",
    "    # Sort recipes by score (descending) and return top_k.\n",
    "    recommended = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 5. Process PP_recipes.csv for Content-Based Filtering\n",
    "#########################################\n",
    "# Expected columns in PP_recipes.csv:\n",
    "#  - id               : Recipe ID\n",
    "#  - name_tokens      : BPE-tokenized recipe name (string representation of list)\n",
    "#  - ingredient_tokens: BPE-tokenized ingredients (string representation of a list of lists)\n",
    "#  - steps_tokens     : BPE-tokenized steps (string representation of list)\n",
    "\n",
    "# Parse the tokenized fields.\n",
    "recipes_df['name_tokens'] = recipes_df['name_tokens'].apply(ast.literal_eval)\n",
    "recipes_df['ingredient_tokens'] = recipes_df['ingredient_tokens'].apply(ast.literal_eval)\n",
    "recipes_df['steps_tokens'] = recipes_df['steps_tokens'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample combined recipe text:\n",
      "       id                                      combined_text\n",
      "0  424415  40480 37229 2911 1019 249 6878 6878 2839 1781 ...\n",
      "1  146223  40480 18376 7056 246 1531 2032 40481 17918 259...\n",
      "2  312329  40480 21044 16954 8294 556 10837 40481 5867 24...\n",
      "3   74301  40480 10025 31156 40481 1270 1645 28447 21601 ...\n",
      "4   76272  40480 17841 252 782 2373 1641 2373 252 40481 1...\n"
     ]
    }
   ],
   "source": [
    "# Combine the tokens into one text for each recipe.\n",
    "def combine_recipe_text(row):\n",
    "    # Convert each token in name_tokens to a string.\n",
    "    name_text = \" \".join([str(token) for token in row['name_tokens']])\n",
    "    \n",
    "    # For ingredient_tokens, each element is a list; convert inner tokens to string.\n",
    "    ingredient_text = \" \".join([\" \".join([str(tok) for tok in lst]) for lst in row['ingredient_tokens']])\n",
    "    \n",
    "    # Convert each token in steps_tokens to a string.\n",
    "    steps_text = \" \".join([str(token) for token in row['steps_tokens']])\n",
    "    \n",
    "    return name_text + \" \" + ingredient_text + \" \" + steps_text\n",
    "\n",
    "recipes_df['combined_text'] = recipes_df.apply(combine_recipe_text, axis=1)\n",
    "print(\"\\nSample combined recipe text:\")\n",
    "print(recipes_df[['id', 'combined_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Steve\\.cache\\huggingface\\hub\\models--openai-gpt. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIGPTModel(\n",
       "  (tokens_embed): Embedding(40478, 768)\n",
       "  (positions_embed): Embedding(512, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x Block(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D(nf=2304, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=768)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Conv1D(nf=3072, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=3072)\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################################\n",
    "# 6. Compute Recipe Embeddings Using OpenAIGPT\n",
    "#########################################\n",
    "# Initialize the GPT tokenizer and model.\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')\n",
    "model = OpenAIGPTModel.from_pretrained('openai-gpt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, max_length=512):\n",
    "    \"\"\"\n",
    "    Compute an embedding for the given text using the OpenAIGPT model.\n",
    "    Uses mean pooling over the last hidden state.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=max_length)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embedding.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     recipe_embeddings[rid] \u001b[38;5;241m=\u001b[39m emb\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[25], line 8\u001b[0m, in \u001b[0;36mget_embedding\u001b[1;34m(text, max_length)\u001b[0m\n\u001b[0;32m      6\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39mmax_length)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 8\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m embedding \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedding\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\transformers\\models\\openai\\modeling_openai.py:501\u001b[0m, in \u001b[0;36mOpenAIGPTModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[0;32m    499\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m--> 501\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\transformers\\models\\openai\\modeling_openai.py:249\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x, attention_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, head_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 249\u001b[0m     attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m     a \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    257\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(x \u001b[38;5;241m+\u001b[39m a)\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\transformers\\models\\openai\\modeling_openai.py:207\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, x, attention_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, head_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 207\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m     query, key, value \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_size, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    209\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_heads(query)\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\transformers\\pytorch_utils.py:124\u001b[0m, in \u001b[0;36mConv1D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    123\u001b[0m     size_out \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnf,)\n\u001b[1;32m--> 124\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(size_out)\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute embeddings for recipes and store in a dictionary (key: recipe id)\n",
    "recipe_embeddings = {}\n",
    "for idx, row in recipes_df.iterrows():\n",
    "    rid = row['id']\n",
    "    text = row['combined_text']\n",
    "    try:\n",
    "        emb = get_embedding(text)\n",
    "        recipe_embeddings[rid] = emb\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing recipe {rid}: {e}\")\n",
    "print(\"\\nComputed embeddings for\", len(recipe_embeddings), \"recipes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Open a file and use dump() \n",
    "with open(r'D:\\UKW_work\\code\\recipe_recommender_system\\temp\\recipe_embeddings.pkl', 'wb') as file:       \n",
    "    # A new file will be created \n",
    "    pickle.dump(recipe_embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 7. Build User Profiles for Content-Based Filtering\n",
    "#########################################\n",
    "# Assume a user \"likes\" a recipe if the rating is high (e.g., >= 4).\n",
    "user_profiles = {}\n",
    "rating_threshold = 4\n",
    "for user in range(n_users):\n",
    "    # Get recipes rated highly by this user.\n",
    "    user_data = interactions_df[interactions_df['user_id'] == user]\n",
    "    liked_recipes = user_data[user_data['rating'] >= rating_threshold]['recipe_id'].tolist()\n",
    "    # Collect embeddings if available.\n",
    "    embeddings = [recipe_embeddings[rid] for rid in liked_recipes if rid in recipe_embeddings]\n",
    "    if embeddings:\n",
    "        stacked = torch.stack(embeddings)\n",
    "        user_profiles[user] = stacked.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_content_based(user_id, top_k=5):\n",
    "    \"\"\"\n",
    "    Recommend recipes using content-based filtering.\n",
    "    Computes cosine similarity between the user's profile and each recipe embedding.\n",
    "    Excludes recipes the user has already interacted with.\n",
    "    \"\"\"\n",
    "    if user_id not in user_profiles:\n",
    "        return []\n",
    "    profile = user_profiles[user_id]\n",
    "    scores = {}\n",
    "    already_rated = set(interactions_df[interactions_df['user_id'] == user_id]['recipe_id'])\n",
    "    for rid, emb in recipe_embeddings.items():\n",
    "        if rid in already_rated:\n",
    "            continue\n",
    "        sim = F.cosine_similarity(profile, emb, dim=0)\n",
    "        scores[rid] = sim.item()\n",
    "    recommended = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return recommended\n",
    "\n",
    "#########################################\n",
    "# 8. Hybrid Recommendation: Combine Both Approaches\n",
    "#########################################\n",
    "def recommend_hybrid(user_id, top_k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Hybrid recommender that combines collaborative and content-based scores.\n",
    "    alpha: weight for the collaborative score, (1 - alpha) for the content-based score.\n",
    "    \"\"\"\n",
    "    collab_recs = recommend_collaborative(user_id, top_k=top_k*2)\n",
    "    content_recs = recommend_content_based(user_id, top_k=top_k*2)\n",
    "    \n",
    "    # Convert recommendations to dictionaries.\n",
    "    collab_dict = dict(collab_recs)\n",
    "    content_dict = dict(content_recs)\n",
    "    \n",
    "    combined_scores = {}\n",
    "    candidate_recipes = set(collab_dict.keys()).union(set(content_dict.keys()))\n",
    "    for rid in candidate_recipes:\n",
    "        c_score = collab_dict.get(rid, 0)\n",
    "        ct_score = content_dict.get(rid, 0)\n",
    "        combined_scores[rid] = alpha * c_score + (1 - alpha) * ct_score\n",
    "    hybrid_recs = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return hybrid_recs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 9. Example: Generate Recommendations for a Sample User\n",
    "#########################################\n",
    "sample_user = 0  # For example, user 0\n",
    "print(\"\\n--- Collaborative Filtering Recommendations for User\", sample_user, \"---\")\n",
    "print(recommend_collaborative(sample_user, top_k=5))\n",
    "\n",
    "print(\"\\n--- Content-Based Recommendations for User\", sample_user, \"---\")\n",
    "print(recommend_content_based(sample_user, top_k=5))\n",
    "\n",
    "print(\"\\n--- Hybrid Recommendations for User\", sample_user, \"---\")\n",
    "print(recommend_hybrid(sample_user, top_k=5, alpha=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'all-MiniLM-L6-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.6.1/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.3.min.js\", \"https://cdn.holoviz.org/panel/1.6.1/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='429621d2-1086-4ae4-806c-6b60eb7b4a04'>\n",
       "  <div id=\"ec69d039-b0a1-4875-8f0a-90c9d2d315b3\" data-root-id=\"429621d2-1086-4ae4-806c-6b60eb7b4a04\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"7ce1fe18-93a9-461a-923d-061f68afb1ee\":{\"version\":\"3.6.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"429621d2-1086-4ae4-806c-6b60eb7b4a04\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"002ac65d-9e12-43c5-9c3b-769d058b7994\",\"attributes\":{\"plot_id\":\"429621d2-1086-4ae4-806c-6b60eb7b4a04\",\"comm_id\":\"a8b8d50b5362436bba2df1d5abd5fe13\",\"client_comm_id\":\"b7e686f516614e3a942baa1db058d838\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"7ce1fe18-93a9-461a-923d-061f68afb1ee\",\"roots\":{\"429621d2-1086-4ae4-806c-6b60eb7b4a04\":\"ec69d039-b0a1-4875-8f0a-90c9d2d315b3\"},\"root_ids\":[\"429621d2-1086-4ae4-806c-6b60eb7b4a04\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "429621d2-1086-4ae4-806c-6b60eb7b4a04"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import hvplot.pandas  # Provides hvplot accessor to Pandas DataFrames\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "DATA_DIR = Path(r\"D:\\UKW_work\\code\\recipe_recommender_system\\data\\food_com_GeniusKitchen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shiva\\miniconda\\envs\\recipe\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "# Instead of using OpenAIGPT, we import SentenceTransformer:\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP_users.csv columns: ['u', 'techniques', 'items', 'n_items', 'ratings', 'n_ratings']\n",
      "PP_users.csv shape: (25076, 6)\n",
      "PP_recipes.csv columns: ['id', 'i', 'name_tokens', 'ingredient_tokens', 'steps_tokens', 'techniques', 'calorie_level', 'ingredient_ids']\n",
      "PP_recipes.csv shape: (178265, 8)\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 1. Load and Explore the Data Files\n",
    "#########################################\n",
    "# Load the CSV files (adjust file paths as needed)\n",
    "users_df = pd.read_csv(DATA_DIR / 'PP_users.csv')\n",
    "recipes_df = pd.read_csv(DATA_DIR /  'PP_recipes.csv')\n",
    "\n",
    "print(\"PP_users.csv columns:\", users_df.columns.tolist())\n",
    "print(\"PP_users.csv shape:\", users_df.shape)\n",
    "print(\"PP_recipes.csv columns:\", recipes_df.columns.tolist())\n",
    "print(\"PP_recipes.csv shape:\", recipes_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample interactions:\n",
      "   user_id  recipe_id  rating\n",
      "0        0       1118     5.0\n",
      "1        0      27680     5.0\n",
      "2        0      32541     5.0\n",
      "3        0     137353     5.0\n",
      "4        0      16428     5.0\n",
      "Total interactions: 698901\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 2. Process PP_users.csv into Interaction Data\n",
    "#########################################\n",
    "# Expected columns in PP_users.csv:\n",
    "#  - u         : user id (contiguous integers)\n",
    "#  - items     : recipes interacted with (string representation of a list)\n",
    "#  - ratings   : ratings given (string representation of a list)\n",
    "\n",
    "# Convert the string representations into actual lists.\n",
    "users_df['items'] = users_df['items'].apply(ast.literal_eval)\n",
    "users_df['ratings'] = users_df['ratings'].apply(ast.literal_eval)\n",
    "\n",
    "# Build an \"exploded\" interactions DataFrame: one row per (user, recipe, rating)\n",
    "interaction_list = []\n",
    "for _, row in users_df.iterrows():\n",
    "    user_id = row['u']\n",
    "    for recipe_id, rating in zip(row['items'], row['ratings']):\n",
    "        interaction_list.append({'user_id': user_id, 'recipe_id': recipe_id, 'rating': rating})\n",
    "interactions_df = pd.DataFrame(interaction_list)\n",
    "print(\"\\nSample interactions:\")\n",
    "print(interactions_df.head())\n",
    "print(\"Total interactions:\", interactions_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of users: 25076, Number of recipes: 178263\n",
      "User-Item Sparse Matrix shape: (25076, 178263)\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 3. Build a Sparse Userâ€“Item Rating Matrix\n",
    "#########################################\n",
    "# Determine the number of users and recipes.\n",
    "n_users = interactions_df['user_id'].max() + 1\n",
    "n_recipes = interactions_df['recipe_id'].max() + 1\n",
    "print(f\"\\nNumber of users: {n_users}, Number of recipes: {n_recipes}\")\n",
    "\n",
    "# Create arrays for constructing a sparse matrix.\n",
    "row_indices = interactions_df['user_id'].values\n",
    "col_indices = interactions_df['recipe_id'].values\n",
    "ratings = interactions_df['rating'].values\n",
    "\n",
    "# Build a CSR (Compressed Sparse Row) matrix.\n",
    "user_item_sparse = csr_matrix((ratings, (row_indices, col_indices)), shape=(n_users, n_recipes))\n",
    "print(\"User-Item Sparse Matrix shape:\", user_item_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 4. Collaborative Filtering: On-The-Fly Similarity\n",
    "#########################################\n",
    "def recommend_collaborative(user_id, top_k=5):\n",
    "    \"\"\"\n",
    "    Recommend recipes for a given user using collaborative filtering.\n",
    "    Computes cosine similarity on the fly between the target user's vector and all user vectors.\n",
    "    Then, aggregates ratings from similar users (weighted by similarity) to score recipes.\n",
    "    Excludes recipes already rated by the target user.\n",
    "    \"\"\"\n",
    "    # Get target user's vector (1 x n_recipes)\n",
    "    user_vec = user_item_sparse.getrow(user_id)\n",
    "    # Compute cosine similarity between this user and all users.\n",
    "    sim_scores = cosine_similarity(user_vec, user_item_sparse).flatten()\n",
    "    \n",
    "    # Compute a weighted score for each recipe.\n",
    "    weighted_scores = user_item_sparse.T.dot(sim_scores)\n",
    "    # Normalize by the sum of similarity scores.\n",
    "    weighted_scores = weighted_scores / (sim_scores.sum() + 1e-8)\n",
    "    \n",
    "    # Exclude recipes already rated by the user.\n",
    "    user_rated = set(interactions_df[interactions_df['user_id'] == user_id]['recipe_id'])\n",
    "    candidate_indices = [i for i in range(n_recipes) if i not in user_rated]\n",
    "    \n",
    "    candidate_scores = {recipe: weighted_scores[recipe] for recipe in candidate_indices}\n",
    "    recommended = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample combined recipe text:\n",
      "       id                                      combined_text\n",
      "0  424415  40480 37229 2911 1019 249 6878 6878 2839 1781 ...\n",
      "1  146223  40480 18376 7056 246 1531 2032 40481 17918 259...\n",
      "2  312329  40480 21044 16954 8294 556 10837 40481 5867 24...\n",
      "3   74301  40480 10025 31156 40481 1270 1645 28447 21601 ...\n",
      "4   76272  40480 17841 252 782 2373 1641 2373 252 40481 1...\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 5. Process PP_recipes.csv for Content-Based Filtering\n",
    "#########################################\n",
    "# Expected columns in PP_recipes.csv:\n",
    "#  - id               : Recipe ID\n",
    "#  - name_tokens      : BPE-tokenized recipe name (string representation of list)\n",
    "#  - ingredient_tokens: BPE-tokenized ingredients (string representation of a list of lists)\n",
    "#  - steps_tokens     : BPE-tokenized steps (string representation of list)\n",
    "\n",
    "# Parse the tokenized fields.\n",
    "recipes_df['name_tokens'] = recipes_df['name_tokens'].apply(ast.literal_eval)\n",
    "recipes_df['ingredient_tokens'] = recipes_df['ingredient_tokens'].apply(ast.literal_eval)\n",
    "recipes_df['steps_tokens'] = recipes_df['steps_tokens'].apply(ast.literal_eval)\n",
    "\n",
    "# Combine the tokens into one text for each recipe.\n",
    "def combine_recipe_text(row):\n",
    "    # Convert tokens to strings in case some tokens are non-string (e.g., integers)\n",
    "    name_text = \" \".join([str(token) for token in row['name_tokens']])\n",
    "    ingredient_text = \" \".join([\" \".join([str(tok) for tok in lst]) for lst in row['ingredient_tokens']])\n",
    "    steps_text = \" \".join([str(token) for token in row['steps_tokens']])\n",
    "    return name_text + \" \" + ingredient_text + \" \" + steps_text\n",
    "\n",
    "recipes_df['combined_text'] = recipes_df.apply(combine_recipe_text, axis=1)\n",
    "print(\"\\nSample combined recipe text:\")\n",
    "print(recipes_df[['id', 'combined_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# 6. Compute Recipe Embeddings Using SentenceTransformer\n",
    "#########################################\n",
    "# Initialize the SentenceTransformer model (all-MiniLM-L6-v2) for fast, CPU-friendly embeddings.\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# We now compute embeddings in a batched manner.\n",
    "# Create lists for recipe IDs and combined texts.\n",
    "recipe_ids = recipes_df['id'].tolist()\n",
    "recipe_texts = recipes_df['combined_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2786/2786 [3:13:14<00:00,  4.16s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computed embeddings for 178265 recipes.\n"
     ]
    }
   ],
   "source": [
    "# Compute embeddings with the SentenceTransformer model.\n",
    "# Set convert_to_tensor=True to get PyTorch tensors.\n",
    "embeddings = embedding_model.encode(recipe_texts, batch_size=64, show_progress_bar=True, convert_to_tensor=True)\n",
    "\n",
    "# Store embeddings in a dictionary (key: recipe id)\n",
    "recipe_embeddings = {rid: emb for rid, emb in zip(recipe_ids, embeddings)}\n",
    "print(\"\\nComputed embeddings for\", len(recipe_embeddings), \"recipes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to D:\\UKW_work\\code\\recipe_recommender_system\\temp\\recipes_embeddings\\recipe_embeddings_all-MiniLM-L6-v2.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "TEMP_DIR = Path(r'D:\\UKW_work\\code\\recipe_recommender_system\\temp')\n",
    "RECIPE_EMBD_DIR = TEMP_DIR / 'recipes_embeddings'\n",
    "USER_PROFILE_EMBD_DIR = TEMP_DIR / 'user_profile_embeddings'\n",
    "\n",
    "\n",
    "embd_save_path = RECIPE_EMBD_DIR / 'recipe_combined_text_embeddings_all-MiniLM-L6-v2.pt'\n",
    "# Save the dictionary containing recipe embeddings\n",
    "torch.save(recipe_embeddings, embd_save_path)\n",
    "print(f\"Embeddings saved to {embd_save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25076 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25076/25076 [01:08<00:00, 364.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "#########################################\n",
    "# 7. Build User Profiles for Content-Based Filtering\n",
    "#########################################\n",
    "# Assume a user \"likes\" a recipe if the rating is high (e.g., >= 4).\n",
    "user_profiles = {}\n",
    "rating_threshold = 4\n",
    "for user in tqdm(range(n_users)):\n",
    "    # Get recipes rated highly by this user.\n",
    "    user_data = interactions_df[interactions_df['user_id'] == user]\n",
    "    liked_recipes = user_data[user_data['rating'] >= rating_threshold]['recipe_id'].tolist()\n",
    "    # Collect embeddings if available.\n",
    "    embeddings_list = [recipe_embeddings[rid] for rid in liked_recipes if rid in recipe_embeddings]\n",
    "    if embeddings_list:\n",
    "        stacked = torch.stack(embeddings_list)\n",
    "        user_profiles[user] = stacked.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Profile saved to D:\\UKW_work\\code\\recipe_recommender_system\\temp\\user_profile_embeddings\\user_profiles_embeddings_all-MiniLM-L6-v2.pt\n"
     ]
    }
   ],
   "source": [
    "user_profiles_save_path = USER_PROFILE_EMBD_DIR / 'user_profiles_embeddings_all-MiniLM-L6-v2.pt'\n",
    "# Save the dictionary containing recipe embeddings\n",
    "torch.save(user_profiles, user_profiles_save_path)\n",
    "print(f\"User Profile saved to {user_profiles_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recommend_content_based(user_id, top_k=5):\n",
    "    \"\"\"\n",
    "    Recommend recipes using content-based filtering.\n",
    "    Computes cosine similarity between the user's profile and each recipe embedding.\n",
    "    Excludes recipes the user has already interacted with.\n",
    "    \"\"\"\n",
    "    if user_id not in user_profiles:\n",
    "        return []\n",
    "    profile = user_profiles[user_id]\n",
    "    scores = {}\n",
    "    already_rated = set(interactions_df[interactions_df['user_id'] == user_id]['recipe_id'])\n",
    "    for rid, emb in recipe_embeddings.items():\n",
    "        if rid in already_rated:\n",
    "            continue\n",
    "        sim = F.cosine_similarity(profile, emb, dim=0)\n",
    "        scores[rid] = sim.item()\n",
    "    recommended = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return recommended\n",
    "\n",
    "#########################################\n",
    "# 8. Hybrid Recommendation: Combine Both Approaches\n",
    "#########################################\n",
    "def recommend_hybrid(user_id, top_k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Hybrid recommender that combines collaborative and content-based scores.\n",
    "    alpha: weight for the collaborative score, (1 - alpha) for the content-based score.\n",
    "    \"\"\"\n",
    "    collab_recs = recommend_collaborative(user_id, top_k=top_k*2)\n",
    "    content_recs = recommend_content_based(user_id, top_k=top_k*2)\n",
    "    \n",
    "    # Convert recommendations to dictionaries.\n",
    "    collab_dict = dict(collab_recs)\n",
    "    content_dict = dict(content_recs)\n",
    "    \n",
    "    combined_scores = {}\n",
    "    candidate_recipes = set(collab_dict.keys()).union(set(content_dict.keys()))\n",
    "    for rid in candidate_recipes:\n",
    "        c_score = collab_dict.get(rid, 0)\n",
    "        ct_score = content_dict.get(rid, 0)\n",
    "        combined_scores[rid] = alpha * c_score + (1 - alpha) * ct_score\n",
    "    hybrid_recs = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return hybrid_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Collaborative Filtering Recommendations for User 0 ---\n",
      "[(135961, np.float64(0.4032051223097654)), (134610, np.float64(0.3209369091004125)), (99787, np.float64(0.31785938317405305)), (127080, np.float64(0.28640487761433614)), (52334, np.float64(0.2702166199654352))]\n",
      "\n",
      "--- Content-Based Recommendations for User 0 ---\n",
      "[(281152, 0.9963469505310059), (294720, 0.9961875081062317), (312189, 0.9961854815483093), (64667, 0.9961628317832947), (91009, 0.9961289167404175)]\n",
      "\n",
      "--- Hybrid Recommendations for User 0 ---\n",
      "[(281152, 0.49817347526550293), (294720, 0.49809375405311584), (312189, 0.49809274077415466), (64667, 0.49808141589164734), (91009, 0.49806445837020874)]\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# 9. Example: Generate Recommendations for a Sample User\n",
    "#########################################\n",
    "sample_user = 0  # For example, user 0\n",
    "print(\"\\n--- Collaborative Filtering Recommendations for User\", sample_user, \"---\")\n",
    "print(recommend_collaborative(sample_user, top_k=5))\n",
    "\n",
    "print(\"\\n--- Content-Based Recommendations for User\", sample_user, \"---\")\n",
    "print(recommend_content_based(sample_user, top_k=5))\n",
    "\n",
    "print(\"\\n--- Hybrid Recommendations for User\", sample_user, \"---\")\n",
    "print(recommend_hybrid(sample_user, top_k=5, alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set data: Get Test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DATA_DIR = Path(r\"D:\\UKW_work\\code\\recipe_recommender_system\\data\\food_com_GeniusKitchen\")\n",
    "\n",
    "token_interactions_train_path = DATA_DIR / 'interactions_train.csv'\n",
    "token_interactions_val_path = DATA_DIR / 'interactions_validation.csv'\n",
    "token_interactions_test_path = DATA_DIR / 'interactions_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User ID,\n",
    "\n",
    "recipe_id\n",
    "Recipe ID\n",
    "\n",
    "date\n",
    "Date of interaction\n",
    "\n",
    "rating\n",
    "Rating given\n",
    "\n",
    "u\n",
    "User ID, mapped to contiguous integers from 0\n",
    "\n",
    "i\n",
    "Recipe ID, mapped to contiguous integers from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================\n",
    "#  Split     # Users    # Recipes # Actions Sparsity\n",
    "#=====================================================\n",
    "# Train     25,076      160,901     698,901     99.983%\n",
    "# Dev       7,023       6,621       7,023       â€“\n",
    "# Test      12,455      11,695      12,455       â€“\n",
    "# ====================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2046</td>\n",
       "      <td>4684</td>\n",
       "      <td>2000-02-25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22095</td>\n",
       "      <td>44367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2046</td>\n",
       "      <td>517</td>\n",
       "      <td>2000-02-25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22095</td>\n",
       "      <td>87844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1773</td>\n",
       "      <td>7435</td>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24732</td>\n",
       "      <td>138181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1773</td>\n",
       "      <td>278</td>\n",
       "      <td>2000-03-13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24732</td>\n",
       "      <td>93054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2046</td>\n",
       "      <td>3431</td>\n",
       "      <td>2000-04-07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22095</td>\n",
       "      <td>101723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698896</th>\n",
       "      <td>926904</td>\n",
       "      <td>457971</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13681</td>\n",
       "      <td>141067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698897</th>\n",
       "      <td>2002312797</td>\n",
       "      <td>27208</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14897</td>\n",
       "      <td>99787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698898</th>\n",
       "      <td>1290903</td>\n",
       "      <td>131607</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11605</td>\n",
       "      <td>76163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698899</th>\n",
       "      <td>226867</td>\n",
       "      <td>363072</td>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3604</td>\n",
       "      <td>29101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698900</th>\n",
       "      <td>2000498330</td>\n",
       "      <td>314535</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2248</td>\n",
       "      <td>21514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>698901 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id  recipe_id        date  rating      u       i\n",
       "0             2046       4684  2000-02-25     5.0  22095   44367\n",
       "1             2046        517  2000-02-25     5.0  22095   87844\n",
       "2             1773       7435  2000-03-13     5.0  24732  138181\n",
       "3             1773        278  2000-03-13     4.0  24732   93054\n",
       "4             2046       3431  2000-04-07     5.0  22095  101723\n",
       "...            ...        ...         ...     ...    ...     ...\n",
       "698896      926904     457971  2018-12-18     5.0  13681  141067\n",
       "698897  2002312797      27208  2018-12-18     5.0  14897   99787\n",
       "698898     1290903     131607  2018-12-18     5.0  11605   76163\n",
       "698899      226867     363072  2018-12-18     5.0   3604   29101\n",
       "698900  2000498330     314535  2018-12-19     5.0   2248   21514\n",
       "\n",
       "[698901 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(token_interactions_train_path)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8937</td>\n",
       "      <td>44551</td>\n",
       "      <td>2005-12-23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>173538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56680</td>\n",
       "      <td>126118</td>\n",
       "      <td>2006-10-07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>177847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>349752</td>\n",
       "      <td>219596</td>\n",
       "      <td>2008-04-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>89896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628951</td>\n",
       "      <td>82783</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45</td>\n",
       "      <td>172637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92816</td>\n",
       "      <td>435013</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52</td>\n",
       "      <td>177935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12450</th>\n",
       "      <td>101053</td>\n",
       "      <td>179011</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25054</td>\n",
       "      <td>130258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12451</th>\n",
       "      <td>252205</td>\n",
       "      <td>81398</td>\n",
       "      <td>2005-12-26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25055</td>\n",
       "      <td>152255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12452</th>\n",
       "      <td>624305</td>\n",
       "      <td>142984</td>\n",
       "      <td>2011-01-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25057</td>\n",
       "      <td>139864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12453</th>\n",
       "      <td>173575</td>\n",
       "      <td>104842</td>\n",
       "      <td>2004-12-18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25059</td>\n",
       "      <td>140646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12454</th>\n",
       "      <td>1249650</td>\n",
       "      <td>287280</td>\n",
       "      <td>2009-04-28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25070</td>\n",
       "      <td>166028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12455 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  recipe_id        date  rating      u       i\n",
       "0         8937      44551  2005-12-23     4.0      2  173538\n",
       "1        56680     126118  2006-10-07     4.0     16  177847\n",
       "2       349752     219596  2008-04-12     0.0     26   89896\n",
       "3       628951      82783  2007-11-13     2.0     45  172637\n",
       "4        92816     435013  2013-07-31     3.0     52  177935\n",
       "...        ...        ...         ...     ...    ...     ...\n",
       "12450   101053     179011  2009-01-03     5.0  25054  130258\n",
       "12451   252205      81398  2005-12-26     2.0  25055  152255\n",
       "12452   624305     142984  2011-01-15     1.0  25057  139864\n",
       "12453   173575     104842  2004-12-18     3.0  25059  140646\n",
       "12454  1249650     287280  2009-04-28     4.0  25070  166028\n",
       "\n",
       "[12455 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(token_interactions_test_path)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8937</td>\n",
       "      <td>2005-12-23</td>\n",
       "      <td>44551</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56680</td>\n",
       "      <td>2006-10-07</td>\n",
       "      <td>126118</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>349752</td>\n",
       "      <td>2008-04-12</td>\n",
       "      <td>219596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628951</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>82783</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92816</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>435013</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12450</th>\n",
       "      <td>101053</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>179011</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12451</th>\n",
       "      <td>252205</td>\n",
       "      <td>2005-12-26</td>\n",
       "      <td>81398</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12452</th>\n",
       "      <td>624305</td>\n",
       "      <td>2011-01-15</td>\n",
       "      <td>142984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12453</th>\n",
       "      <td>173575</td>\n",
       "      <td>2004-12-18</td>\n",
       "      <td>104842</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12454</th>\n",
       "      <td>1249650</td>\n",
       "      <td>2009-04-28</td>\n",
       "      <td>287280</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12455 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id        date  recipe_id  rating\n",
       "0         8937  2005-12-23      44551     4.0\n",
       "1        56680  2006-10-07     126118     4.0\n",
       "2       349752  2008-04-12     219596     0.0\n",
       "3       628951  2007-11-13      82783     2.0\n",
       "4        92816  2013-07-31     435013     3.0\n",
       "...        ...         ...        ...     ...\n",
       "12450   101053  2009-01-03     179011     5.0\n",
       "12451   252205  2005-12-26      81398     2.0\n",
       "12452   624305  2011-01-15     142984     1.0\n",
       "12453   173575  2004-12-18     104842     3.0\n",
       "12454  1249650  2009-04-28     287280     4.0\n",
       "\n",
       "[12455 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['user_id', 'date', 'recipe_id', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76535</td>\n",
       "      <td>33627</td>\n",
       "      <td>2005-02-15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>177317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160497</td>\n",
       "      <td>75307</td>\n",
       "      <td>2005-10-24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23</td>\n",
       "      <td>170785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>930021</td>\n",
       "      <td>100961</td>\n",
       "      <td>2008-11-30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31</td>\n",
       "      <td>165555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58439</td>\n",
       "      <td>154105</td>\n",
       "      <td>2007-03-24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44</td>\n",
       "      <td>177453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>628951</td>\n",
       "      <td>14525</td>\n",
       "      <td>2008-02-16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45</td>\n",
       "      <td>142367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>557416</td>\n",
       "      <td>247915</td>\n",
       "      <td>2007-10-25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25006</td>\n",
       "      <td>164841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7019</th>\n",
       "      <td>218411</td>\n",
       "      <td>116676</td>\n",
       "      <td>2005-09-21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25008</td>\n",
       "      <td>117202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>587445</td>\n",
       "      <td>206493</td>\n",
       "      <td>2008-07-16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25009</td>\n",
       "      <td>117301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>1724643</td>\n",
       "      <td>65883</td>\n",
       "      <td>2011-11-08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25047</td>\n",
       "      <td>131974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>252205</td>\n",
       "      <td>83174</td>\n",
       "      <td>2005-12-26</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25055</td>\n",
       "      <td>152010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7023 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  recipe_id        date  rating      u       i\n",
       "0       76535      33627  2005-02-15     4.0      5  177317\n",
       "1      160497      75307  2005-10-24     4.0     23  170785\n",
       "2      930021     100961  2008-11-30     4.0     31  165555\n",
       "3       58439     154105  2007-03-24     4.0     44  177453\n",
       "4      628951      14525  2008-02-16     5.0     45  142367\n",
       "...       ...        ...         ...     ...    ...     ...\n",
       "7018   557416     247915  2007-10-25     5.0  25006  164841\n",
       "7019   218411     116676  2005-09-21     3.0  25008  117202\n",
       "7020   587445     206493  2008-07-16     5.0  25009  117301\n",
       "7021  1724643      65883  2011-11-08     5.0  25047  131974\n",
       "7022   252205      83174  2005-12-26     5.0  25055  152010\n",
       "\n",
       "[7023 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv(token_interactions_val_path)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common user IDs: 12455\n"
     ]
    }
   ],
   "source": [
    "common_ids = set(test_df['user_id']) & set(train_df['user_id'])\n",
    "print(\"Number of common user IDs:\", len(common_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common recipe IDs: 0\n"
     ]
    }
   ],
   "source": [
    "common_ids = set(test_df['recipe_id']) & set(train_df['recipe_id'])\n",
    "print(\"Number of common recipe IDs:\", len(common_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231637, (231637, 12))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### COLUMNS ####\n",
    "# 1. Recipe name\n",
    "# 2. id: Recipe ID\n",
    "# 3. minutes:  Minutes to prepare recipe\n",
    "# 4. contributor_id: User ID who submitted this recipe\n",
    "# 5. submitted: Date recipe was submitted\n",
    "# 6. tags: Food.com tags for recipe\n",
    "# 7. nutrition:  Nutrition information (calories (#), total fat (PDV), \n",
    "#   sugar (PDV) , sodium (PDV) , protein (PDV) , saturated fat (PDV) , and carbohydrates (PDV))\n",
    "# 8. n_steps:  Number of steps in recipe\n",
    "# 9. steps: Text for recipe steps, in order\n",
    "# 10. description: User-provided description\n",
    "\n",
    "\n",
    "\n",
    "raw_df = pd.read_csv(DATA_DIR / 'RAW_recipes.csv')\n",
    "raw_df['id'].nunique(), raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231637, (1132367, 5))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_usr_df = pd.read_csv(DATA_DIR / 'RAW_interactions.csv')\n",
    "raw_usr_df['recipe_id'].nunique(), raw_usr_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231637, (231637, 12))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['id'].nunique(), raw_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================\n",
    "#  Split     # Users    # Recipes # Actions Sparsity\n",
    "#=====================================================\n",
    "# Train     25,076      160,901     698,901     99.983%\n",
    "# Dev       7,023       6,621       7,023       â€“\n",
    "# Test      12,455      11,695      12,455       â€“\n",
    "# ====================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698901 160901 (698901, 6)\n",
      "7023 6621 (7023, 6)\n",
      "12455 11695 (12455, 6)\n"
     ]
    }
   ],
   "source": [
    "train_recipe_ids = train_df['recipe_id'].to_list()\n",
    "print(len(train_recipe_ids),  train_df['recipe_id'].nunique(),train_df.shape)\n",
    "\n",
    "val_recipe_ids = val_df['recipe_id'].to_list()\n",
    "print(len(val_recipe_ids), val_df['recipe_id'].nunique(), val_df.shape)\n",
    "\n",
    "test_recipe_ids = test_df['recipe_id'].to_list()\n",
    "print(len(test_recipe_ids),test_df['recipe_id'].nunique(), test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179217"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "160901 +6621  + 11695 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "718379"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "698901  + 7023 + 12455 #total user reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160901, 12)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create RAW_recipe_train_df with interactions_train.csv using list of unique recipe_ids\n",
    "\n",
    "# Suppose recipe_ids is your list of recipe IDs to filter by.\n",
    "filtered_df = raw_df[raw_df['id'].isin(train_recipe_ids)]\n",
    "# print(filtered_df)\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test_df = raw_df[raw_df['id'].isin(test_recipe_ids)]\n",
    "# print(filtered_df)\n",
    "filtered_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.core.indexes.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m         objects\u001b[38;5;241m.\u001b[39mappend(\u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopenfile\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.core.indexes.numeric'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "objects = []\n",
    "with (open(r\"D:\\UKW_work\\code\\recipe_recommender_system\\data\\food_com_GeniusKitchen\\ingr_map.pkl\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_ingr</th>\n",
       "      <th>raw_words</th>\n",
       "      <th>processed</th>\n",
       "      <th>len_proc</th>\n",
       "      <th>replaced</th>\n",
       "      <th>count</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium heads bibb or red leaf lettuce, washed,...</td>\n",
       "      <td>13</td>\n",
       "      <td>medium heads bibb or red leaf lettuce, washed,...</td>\n",
       "      <td>73</td>\n",
       "      <td>lettuce</td>\n",
       "      <td>4507</td>\n",
       "      <td>4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mixed baby lettuces and spring greens</td>\n",
       "      <td>6</td>\n",
       "      <td>mixed baby lettuces and spring green</td>\n",
       "      <td>36</td>\n",
       "      <td>lettuce</td>\n",
       "      <td>4507</td>\n",
       "      <td>4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>romaine lettuce leaf</td>\n",
       "      <td>3</td>\n",
       "      <td>romaine lettuce leaf</td>\n",
       "      <td>20</td>\n",
       "      <td>lettuce</td>\n",
       "      <td>4507</td>\n",
       "      <td>4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iceberg lettuce leaf</td>\n",
       "      <td>3</td>\n",
       "      <td>iceberg lettuce leaf</td>\n",
       "      <td>20</td>\n",
       "      <td>lettuce</td>\n",
       "      <td>4507</td>\n",
       "      <td>4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red romaine lettuce</td>\n",
       "      <td>3</td>\n",
       "      <td>red romaine lettuce</td>\n",
       "      <td>19</td>\n",
       "      <td>lettuce</td>\n",
       "      <td>4507</td>\n",
       "      <td>4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11654</th>\n",
       "      <td>soybeans</td>\n",
       "      <td>1</td>\n",
       "      <td>soybean</td>\n",
       "      <td>7</td>\n",
       "      <td>soybean</td>\n",
       "      <td>31</td>\n",
       "      <td>6702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11655</th>\n",
       "      <td>goose</td>\n",
       "      <td>1</td>\n",
       "      <td>goose</td>\n",
       "      <td>5</td>\n",
       "      <td>goose</td>\n",
       "      <td>8</td>\n",
       "      <td>3318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11656</th>\n",
       "      <td>ajwain</td>\n",
       "      <td>1</td>\n",
       "      <td>ajwain</td>\n",
       "      <td>6</td>\n",
       "      <td>ajwain</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11657</th>\n",
       "      <td>brinjals</td>\n",
       "      <td>1</td>\n",
       "      <td>brinjal</td>\n",
       "      <td>7</td>\n",
       "      <td>brinjal</td>\n",
       "      <td>2</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11658</th>\n",
       "      <td>khoya</td>\n",
       "      <td>1</td>\n",
       "      <td>khoya</td>\n",
       "      <td>5</td>\n",
       "      <td>khoya</td>\n",
       "      <td>6</td>\n",
       "      <td>4061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11659 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                raw_ingr  raw_words  \\\n",
       "0      medium heads bibb or red leaf lettuce, washed,...         13   \n",
       "1                  mixed baby lettuces and spring greens          6   \n",
       "2                                   romaine lettuce leaf          3   \n",
       "3                                   iceberg lettuce leaf          3   \n",
       "4                                    red romaine lettuce          3   \n",
       "...                                                  ...        ...   \n",
       "11654                                           soybeans          1   \n",
       "11655                                              goose          1   \n",
       "11656                                             ajwain          1   \n",
       "11657                                           brinjals          1   \n",
       "11658                                              khoya          1   \n",
       "\n",
       "                                               processed  len_proc replaced  \\\n",
       "0      medium heads bibb or red leaf lettuce, washed,...        73  lettuce   \n",
       "1                   mixed baby lettuces and spring green        36  lettuce   \n",
       "2                                   romaine lettuce leaf        20  lettuce   \n",
       "3                                   iceberg lettuce leaf        20  lettuce   \n",
       "4                                    red romaine lettuce        19  lettuce   \n",
       "...                                                  ...       ...      ...   \n",
       "11654                                            soybean         7  soybean   \n",
       "11655                                              goose         5    goose   \n",
       "11656                                             ajwain         6   ajwain   \n",
       "11657                                            brinjal         7  brinjal   \n",
       "11658                                              khoya         5    khoya   \n",
       "\n",
       "       count    id  \n",
       "0       4507  4308  \n",
       "1       4507  4308  \n",
       "2       4507  4308  \n",
       "3       4507  4308  \n",
       "4       4507  4308  \n",
       "...      ...   ...  \n",
       "11654     31  6702  \n",
       "11655      8  3318  \n",
       "11656     13    47  \n",
       "11657      2   750  \n",
       "11658      6  4061  \n",
       "\n",
       "[11659 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_rec_usr = pd.read_pickle(r\"D:\\UKW_work\\code\\recipe_recommender_system\\data\\food_com_GeniusKitchen\\ingr_map.pkl\")\n",
    "map_rec_usr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
